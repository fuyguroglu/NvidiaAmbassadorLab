# LLM Training Lab: Adding New Knowledge to LLMs

A comprehensive training environment for learning modern LLM techniques including RAG, fine-tuning, and optimization strategies. Designed for NVIDIA Ambassador certification preparation with focus on practical, hands-on experience.

## ğŸ¯ Project Goals

This project helps students gain practical experience with:
- **RAG (Retrieval-Augmented Generation)** - Easy-to-use interface for domain-specific Q&A
- **Fine-tuning** - Hands-on examples with parameter-efficient techniques
- **Model Optimization** - Pruning, distillation, and quantization
- **Evaluation** - ROUGE/BLEU, semantic similarity, and LLM-as-a-judge
- **CUDA Acceleration** - Understanding GPU optimization for LLMs

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ 1-rag-basics/              # Simple RAG application (START HERE!)
â”‚   â”œâ”€â”€ app.py                 # Easy-to-use web interface
â”‚   â”œâ”€â”€ rag_simple.py          # Core RAG implementation
â”‚   â”œâ”€â”€ data/                  # Your documents go here
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ 2-fine-tuning/             # Fine-tuning examples
â”‚   â”œâ”€â”€ basic_finetuning.py    # Full fine-tuning example
â”‚   â”œâ”€â”€ peft_lora.py           # Parameter-Efficient Fine-Tuning (LoRA)
â”‚   â”œâ”€â”€ notebooks/             # Interactive Jupyter notebooks
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ 3-synthetic-data/          # Data generation strategies
â”‚   â”œâ”€â”€ generate_qa_pairs.py   # Create Q&A from documents
â”‚   â”œâ”€â”€ diverse_data.py        # Strategies for diverse datasets
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ 4-optimization/            # Model optimization techniques
â”‚   â”œâ”€â”€ pruning.py             # Model pruning examples
â”‚   â”œâ”€â”€ distillation.py        # Knowledge distillation
â”‚   â”œâ”€â”€ quantization.py        # Model quantization
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ 5-decoding-strategies/     # LLM output generation
â”‚   â”œâ”€â”€ sampling_methods.py    # Top-k, top-p, temperature
â”‚   â”œâ”€â”€ beam_search.py         # Beam search implementation
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ 6-evaluation/              # Evaluation techniques
â”‚   â”œâ”€â”€ metrics.py             # ROUGE, BLEU, semantic similarity
â”‚   â”œâ”€â”€ llm_as_judge.py        # LLM-based evaluation
â”‚   â”œâ”€â”€ benchmarking.py        # Performance benchmarking
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ cuda-optimization/         # CUDA-specific topics
â”‚   â”œâ”€â”€ gpu_profiling.py       # Profile GPU usage
â”‚   â”œâ”€â”€ memory_optimization.py # Memory management
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ datasets/                  # Your training materials
â”‚   â”œâ”€â”€ documents/             # Add your PDFs, text files here
â”‚   â””â”€â”€ qa_pairs/              # Training Q&A pairs
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ setup.sh                   # Easy setup script
â””â”€â”€ docs/                      # Comprehensive documentation
    â”œâ”€â”€ CONCEPTS.md            # RAG vs Fine-tuning vs Alignment
    â”œâ”€â”€ NVIDIA_PREP.md         # Ambassador certification prep
    â””â”€â”€ TROUBLESHOOTING.md
```

## ğŸš€ Quick Start (For Non-Technical Users)

### Prerequisites
- NVIDIA GPU (recommended: RTX 3060 or better)
- Python 3.10+
- 16GB+ RAM

### Installation

1. **Clone this repository**
```bash
git clone <repository-url>
cd "Nvidia Ambassador"
```

2. **Run the setup script**
```bash
bash setup.sh
```

3. **Add your documents to `datasets/documents/`**

4. **Start the RAG application**
```bash
cd 1-rag-basics
python app.py
```

5. **Open your browser to** `http://localhost:7860`

That's it! You can now ask questions about your documents!

## ğŸ“š Learning Path

### Week 1: RAG Basics
- [ ] Understand what RAG is and why it's useful
- [ ] Run the RAG application with your documents
- [ ] Try different retrieval strategies
- [ ] Compare RAG vs traditional search

### Week 2: Fine-tuning Fundamentals
- [ ] Learn difference between RAG and fine-tuning
- [ ] Run basic fine-tuning on small model
- [ ] Understand training loss and evaluation metrics
- [ ] Experiment with hyperparameters

### Week 3: Parameter-Efficient Fine-Tuning (PEFT)
- [ ] Implement LoRA (Low-Rank Adaptation)
- [ ] Compare full fine-tuning vs PEFT
- [ ] Measure GPU memory usage differences
- [ ] Understand trade-offs

### Week 4: Synthetic Data Generation
- [ ] Generate Q&A pairs from your documents
- [ ] Create diverse training examples
- [ ] Evaluate data quality
- [ ] Fine-tune with synthetic data

### Week 5: Model Optimization
- [ ] Pruning: Reduce model size
- [ ] Distillation: Transfer knowledge to smaller models
- [ ] Quantization: Reduce precision
- [ ] Benchmark performance vs accuracy

### Week 6: Decoding & Evaluation
- [ ] Experiment with sampling strategies
- [ ] Implement beam search
- [ ] Calculate ROUGE/BLEU scores
- [ ] Set up LLM-as-a-judge evaluation

## ğŸ“ NVIDIA Ambassador Certification Prep

### Required Experience Documentation

As you work through this project, document:

1. **GPU Acceleration Benefits**
   - Measure training time: CPU vs GPU
   - Profile memory usage
   - Demonstrate speedup metrics

2. **Optimization Strategies**
   - Which PEFT methods you used
   - Memory optimization techniques
   - Batch size and gradient accumulation choices

3. **CUDA Challenges**
   - Out-of-memory errors and solutions
   - Multi-GPU training attempts
   - Performance bottlenecks identified

### Key Concepts to Master

- **RAG vs Fine-tuning vs Alignment**
  - RAG: Retrieve relevant docs at inference time
  - Fine-tuning: Update model weights with new data
  - Alignment: RLHF/DPO to align with human preferences

- **Synthetic Data Strategies**
  - Question generation from documents
  - Paraphrasing for diversity
  - Adversarial examples
  - Data augmentation techniques

- **PEFT Techniques**
  - LoRA (Low-Rank Adaptation)
  - QLoRA (Quantized LoRA)
  - Adapter layers
  - Prefix tuning

## ğŸ”§ Technical Stack

- **Framework**: PyTorch + Hugging Face Transformers
- **RAG**: LangChain + ChromaDB
- **PEFT**: Hugging Face PEFT library
- **Evaluation**: NLTK, SacreBLEU, sentence-transformers
- **UI**: Gradio (simple web interface)
- **GPU**: CUDA 12.x with cuDNN

## ğŸ¤ Contributing

Students are encouraged to:
- Share interesting use cases
- Improve the RAG interface
- Add new optimization techniques
- Share evaluation results
- Document CUDA optimization discoveries

## ğŸ“ License

MIT License - Free for educational use

## ğŸ†˜ Getting Help

- Check `docs/TROUBLESHOOTING.md`
- Review `docs/CONCEPTS.md` for theory
- Open an issue on GitHub

---

**Note**: This project is designed for NVIDIA Ambassador certification preparation. Focus on understanding the concepts deeply and documenting your learning journey!
